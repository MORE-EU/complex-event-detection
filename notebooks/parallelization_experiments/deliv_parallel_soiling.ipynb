{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.facecolor']='w'\n",
    "plt.rcParams['savefig.facecolor']='w'\n",
    "%matplotlib inline \n",
    "#from my_functions import *\n",
    "from modules.preprocessing import *\n",
    "#from modules.statistics import *\n",
    "from modules.learning import *\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from modules.experiments import *\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from glob import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the performance of the soiling regression method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=30,threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_wash_start = pd.to_datetime(pd.Series(['2013-03-11 00:00:00', '2013-07-10 00:00:00', '2013-08-14 00:00:00', '2013-08-21 00:00:00', '2013-08-26 00:00:00']))\n",
    "dates_wash_stop = pd.to_datetime(pd.Series(['2013-03-12 00:00:00', '2013-07-11 00:00:00', '2013-08-15 00:00:00', '2013-08-22 00:00:00','2013-08-27 00:00:00']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamesTraining = sorted(glob(os.path.join('/path','folder','training_*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fileArraysTraining = []\n",
    "scaler = MinMaxScaler()\n",
    "for fn in filenamesTraining:\n",
    "    df = pd.read_csv(fn)\n",
    "    df = df.set_index('timestamp')\n",
    "    df = df.dropna()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    fileArraysTraining.append(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Rains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "precipitation = []\n",
    "dates_rain_start = []\n",
    "dates_rain_stop = []\n",
    "for i, df in enumerate(fileArraysTraining):\n",
    "    precipitation.append(pd.concat([pd.Series({min(df.index)-pd.Timedelta('1s'): 0}),df.precipitation, pd.Series({max(df.index)+pd.Timedelta('1s'): 0})]))\n",
    "    precipitation[i].index = pd.to_datetime(precipitation[i].index)\n",
    "    df_dates = pd.DataFrame(index = precipitation[i].index)\n",
    "    df_dates[\"rain_start\"] = precipitation[i][(precipitation[i].shift(-1) > 0) & (precipitation[i] == 0)] # compare current to next\n",
    "    df_dates[\"rain_stop\"] = precipitation[i][(precipitation[i].shift(1) > 0) & (precipitation[i] == 0)] # compare current to prev\n",
    "    dates_rain_start.append(pd.Series(df_dates.rain_start.index[df_dates.rain_start.notna()]))\n",
    "    dates_rain_stop.append(pd.Series(df_dates.rain_stop.index[df_dates.rain_stop.notna()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find change points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(filenamesTraining)\n",
    "w1 = 10  # window of days to train (before the rain)\n",
    "w2 = 5 # window of days to validate (before the rain)\n",
    "w3 = 10 # window of days to test (after the rain)\n",
    "error_br_column = 5 #0=r_squared, 1=mae, 2=me, 3=mape, 4=mpe, 5=median error\n",
    "error_ar_column = 5\n",
    "thrsh = 1\n",
    "w_train = 30\n",
    "feats = ['irradiance', 'mod_temp']\n",
    "target = 'power'\n",
    "#indices = np.empty(len(scores), dtype=int)\n",
    "error_names = {0: \"r_squared\", 1: \"MAE\", 2: \"ME (true-pred)\", 3: \"MAPE\", 4: \"MPE (true-pred)\", 5: \"Median error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "changepoint_ids = []\n",
    "\n",
    "for i, df in enumerate(fileArraysTraining):\n",
    "    p_changepoints_start = (pd.Series(dates_rain_start[i]).sort_values())\n",
    "    p_changepoints_stop = (pd.Series(dates_rain_stop[i]).sort_values())\n",
    "    error_name_br = error_names[error_br_column] \n",
    "    error_name_ar = error_names[error_ar_column]\n",
    "    errors_br = np.empty((len(dates_rain_start[i]), 6))\n",
    "    errors_ar = np.empty((len(dates_rain_start[i]), 6))\n",
    "    scores = np.empty((n, len(dates_rain_start[i])))\n",
    "    \n",
    "    #compute errors using one model per rain\n",
    "    errors_br, errors_ar = errors_at_rains2(df, p_changepoints_start, p_changepoints_stop, target, feats, w1, w2, w3 )\n",
    "    #set threshold on MAPE error before rain\n",
    "    mask1 = (errors_br[:,3]<= 0.05)\n",
    "    #compute scores for the remaining\n",
    "    scores[i] = -(errors_br[:, error_br_column]-errors_ar[:, error_ar_column])/np.abs(errors_br[:, error_ar_column])\n",
    "    scores[i][(~mask1)] = np.finfo('d').min\n",
    "    \n",
    "    #compute indices to the best no_events rains\n",
    "    indices = np.argsort(-scores[i])[:(scores>thrsh).sum()] \n",
    "    changepoint_ids.append(indices) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models after changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models = []\n",
    "for i, df in enumerate(fileArraysTraining): \n",
    "    ref_points = pd.Index(dates_rain_stop[i][changepoint_ids[i]])\n",
    "    model, training_error, validation_error = train_on_reference_points(df, w_train, ref_points, feats, target)\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamesTesting = sorted(glob(os.path.join('/path','folder','testing_*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fileArraysTesting = []\n",
    "scaler = MinMaxScaler()\n",
    "for fn in filenamesTesting:\n",
    "    df = pd.read_csv(fn)\n",
    "    df = df.set_index('timestamp')\n",
    "    df = df.dropna()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    fileArraysTesting.append(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models in new time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelsNewTimeSeries(df, models, feats, target ):\n",
    "    y_pred = predict(df, models, feats, target)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "window = 60\n",
    "i = 0\n",
    "\n",
    "total_running_time = 0.0;\n",
    "running_time = []\n",
    "\n",
    "while i< len(fileArraysTesting[0])-window:\n",
    "    start = time.time()\n",
    "    for j, df in enumerate(fileArraysTesting):\n",
    "        y_pred = predict(df.iloc[i:i+window], models[0], feats, target)\n",
    "        \n",
    "    end = time.time()\n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)   \n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    i = i+window\n",
    "    \n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Batch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelsNewTimeSeriesBatch(batch_data, models, feats, target ):\n",
    "    results = []\n",
    "    for batch_temp in batch_data:\n",
    "        y_pred = predict(batch_temp, models, feats, target)\n",
    "        results.append(y_pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_processing(batch_data, models, feats, target):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch in batch_data:\n",
    "        future = client.submit(trainModelsNewTimeSeriesBatch, batch, models, feats, target )\n",
    "        futures.append(future)\n",
    "    \n",
    "    wait(futures, return_when=\"ALL_COMPLETED\") \n",
    "    end = time.time()\n",
    "    futures = []\n",
    "    \n",
    "    running_time = end- start\n",
    "    \n",
    "    return running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "window = 60\n",
    "i = 0\n",
    "\n",
    "batch_data_size = 3334\n",
    "batch_data = []\n",
    "batch_data_all =[]\n",
    "counter = 0;\n",
    "running_time = []\n",
    "total_running_time = 0.0 \n",
    "\n",
    "while i< len(fileArraysTesting[0])-window:\n",
    "    for j, df in enumerate(fileArraysTesting):\n",
    "        if (counter < batch_data_size):\n",
    "            batch_data.append(df.iloc[i:i+window])\n",
    "            counter = counter +1 \n",
    "                                                                                                    \n",
    "        else:\n",
    "            counter = 0\n",
    "            batch_data_all.append(batch_data)\n",
    "            batch_data = []\n",
    "            batch_data.append( df.iloc[i:i+window])\n",
    "            counter = counter +1\n",
    "    \n",
    "    batch_data_all.append(batch_data)\n",
    "    batch_data =[]\n",
    "    \n",
    "    running_time_temp = parallel_batch_processing(batch_data_all, models[0], feats, target)  \n",
    "    running_time.append(running_time_temp)   \n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    batch_data_all = []\n",
    "\n",
    "    i = i+window\n",
    "    \n",
    "print(\"total_running_time  = \", total_running_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Code without Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelsNewTimeSeriesParallel(df, models, feats, target ):\n",
    "    y_pred = predict(df, models, feats, target)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "window = 60\n",
    "i = 0\n",
    "\n",
    "futures = []\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "while i< len(fileArraysTesting[0])-window:\n",
    "    start = time.time()\n",
    "    for j, df in enumerate(fileArraysTesting):\n",
    "        future = client.submit(trainModelsNewTimeSeriesParallel, df.iloc[i:i+window], models[0], feats, target)\n",
    "        futures.append(future)\n",
    "        \n",
    "    wait(futures, return_when=\"ALL_COMPLETED\") \n",
    "    end = time.time()\n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    futures = []\n",
    "    i = i + window\n",
    "    \n",
    "print(\"total_running_time = \" , total_running_time)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
