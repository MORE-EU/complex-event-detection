{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "#import seaborn as sns\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from modules.preprocessing import *\n",
    "from modules.io import *\n",
    "from modules.learning import *\n",
    "from modules.statistics import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import normalize\n",
    "#import seaborn\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the performance of the yaw misalignment regression method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=30,threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob(os.path.join('/data/data1/synthetic_yaw_data','testing_*.csv')))\n",
    "filenames = filenames[:20000] # load 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data_bins = []\n",
    "counter = 0\n",
    "for f in filenames:\n",
    "    counter = counter +1 \n",
    "    dataset_file =  f\n",
    "    df = load_df(dataset_file)\n",
    "    df = df.set_index('timestamp')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df.columns = df.columns.str.replace('cor. ', '', regex=False)\n",
    "    cols = ['wind speed', 'pitch angle', 'rotor speed', 'active power',\n",
    "            'nacelle direction', 'wind direction', 'theta_d']\n",
    "    df = df[cols]\n",
    "    df[\"y\"] = np.random.randint(low=0, high=10, size=len(df))\n",
    "    test_data.append(df.copy())\n",
    "    \n",
    "\n",
    "    bin_size = 2\n",
    "    min_speed = 0\n",
    "    max_speed = 24\n",
    "    bins = np.arange(min_speed, max_speed, bin_size)\n",
    "    bins = np.append(bins,max_speed)\n",
    "    bin_masks = []\n",
    "    bin_feature = 'wind speed'\n",
    "    for i in range(len(bins) - 1):\n",
    "        mask = (df[bin_feature]>= bins[i]) & (df[bin_feature] < bins[i + 1])\n",
    "        bin_masks.append(mask)\n",
    "    test_data_bins.append(bin_masks.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_file = '/home/dtsitsigkos/more/yaw_windows/deliv_parallel_yaw/Models_Select_Bins1.pickle' \n",
    "scaler_file = '/home/dtsitsigkos/more/yaw_windows/deliv_parallel_yaw/select_bins_scaler.pickle'\n",
    "\n",
    "with open(models_file, 'rb') as file:\n",
    "    all_models_dict = pickle.load(file)\n",
    "    \n",
    "with open(scaler_file, 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_scaled = []\n",
    "for df in test_data:\n",
    "    df_scaled = df.copy().drop(columns=['y']) \n",
    "    df_scaled[df_scaled.columns] = scaler.transform(df_scaled)\n",
    "    df_scaled['y'] = df['y']\n",
    "    df['y_pred'] = np.nan\n",
    "    test_data_scaled.append(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models in new time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_yaw(df, scaler, all_models_dict, bin_masks,df_scaled):\n",
    "    binned_data_dfs = []\n",
    "\n",
    "    for b_no, b in enumerate(bin_masks):\n",
    "        df_temp = df_scaled[bin_masks.iloc[:,b]]\n",
    "        binned_data_dfs.append(df_temp.copy())\n",
    "        \n",
    "    target_feature = 'active power'\n",
    "    \n",
    "    all_evaluation_scores = {}\n",
    "    for dataset_key, dataset_dict in all_models_dict.items():\n",
    "        all_evaluation_scores[dataset_key] = {}\n",
    "        fit_features = dataset_dict['selected_features']\n",
    "        models_dict = dataset_dict['models']\n",
    "        evaluation_scores = {}\n",
    "        for key, models in models_dict.items():\n",
    "            mape_list = []\n",
    "            for bin_n, d in enumerate(binned_data_dfs):\n",
    "                if d.shape[0] >= 10 and models[bin_n] is not None:\n",
    "                    test_preds = predict(d, models[bin_n], fit_features, target_feature)\n",
    "                    r_sq, mae, me, mape, mpe, Me = score(d[target_feature].values, test_preds)\n",
    "                    mape_list.append(mape)\n",
    "                else:\n",
    "                    pass\n",
    "            avg_mape = np.mean(mape_list)\n",
    "            evaluation_scores[key] = avg_mape\n",
    "        all_evaluation_scores[dataset_key].update(evaluation_scores.copy())\n",
    "    min_score = float(\"inf\")\n",
    "    th_s_label = ''\n",
    "    for dataset, dict1 in all_evaluation_scores.items(): \n",
    "        for th_s, evaluation_score in dict1.items(): \n",
    "            sc = evaluation_score\n",
    "            if sc <= min_score:\n",
    "                min_score = sc\n",
    "                th_s_label = np.abs(float(th_s))\n",
    "    indexer = df.index\n",
    "    df.loc[indexer, 'y_pred'] = th_s_label\n",
    "    prediction = np.abs(df['y_pred'])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_running_time =  19454.50767159462\n",
      "CPU times: user 5h 26min 51s, sys: 38min 12s, total: 6h 5min 3s\n",
      "Wall time: 5h 24min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "window = 1440\n",
    "i = 0\n",
    "\n",
    "running_time = []\n",
    "total_running_time = 0.0\n",
    "\n",
    "\n",
    "while i< len(test_data_scaled[0])-window:\n",
    "    \n",
    "    start = time.time()\n",
    "    for df, b_masks, df_scaled in zip(test_data, test_data_bins, test_data_scaled):\n",
    "        test_data_bins_temp = pd.concat(b_masks,axis=1)\n",
    "        test_data_bins_temp.columns = range(12)\n",
    "        res = predict_yaw(df.iloc[i:i+window].copy(), scaler, all_models_dict, test_data_bins_temp.iloc[i:i+window], df_scaled.iloc[i:i+window].copy())\n",
    "    end = time.time()\n",
    "    \n",
    "    running_time_temp = end - start\n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp  \n",
    "    i = i + window\n",
    "    \n",
    "print (\"total_running_time = \", total_running_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Batch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_yaw_batch(df_new, all_models_dict, bin_masks_new,df_scaled_new):\n",
    "    predictions = []\n",
    "    \n",
    "    for df, bin_masks,df_scaled in zip(df_new, bin_masks_new, df_scaled_new):\n",
    "        binned_data_dfs = []\n",
    "        for b_no, b in enumerate(bin_masks):\n",
    "            df_temp = df_scaled[bin_masks.iloc[:,b]]\n",
    "            binned_data_dfs.append(df_temp.copy())\n",
    "\n",
    "        target_feature = 'active power'\n",
    "\n",
    "        all_evaluation_scores = {}\n",
    "        for dataset_key, dataset_dict in all_models_dict.items():\n",
    "            all_evaluation_scores[dataset_key] = {}\n",
    "            fit_features = dataset_dict['selected_features']\n",
    "            models_dict = dataset_dict['models']\n",
    "            evaluation_scores = {}\n",
    "            for key, models in models_dict.items():\n",
    "                mape_list = []\n",
    "                for bin_n, d in enumerate(binned_data_dfs):\n",
    "                    if d.shape[0] >= 10 and models[bin_n] is not None:\n",
    "                        test_preds = predict(d, models[bin_n], fit_features, target_feature)\n",
    "                        r_sq, mae, me, mape, mpe, Me = score(d[target_feature].values, test_preds)\n",
    "                        mape_list.append(mape)\n",
    "                    else:\n",
    "                        pass\n",
    "                avg_mape = np.mean(mape_list)\n",
    "                evaluation_scores[key] = avg_mape\n",
    "            all_evaluation_scores[dataset_key].update(evaluation_scores.copy())\n",
    "        min_score = float(\"inf\")\n",
    "        th_s_label = ''\n",
    "        for dataset, dict1 in all_evaluation_scores.items(): \n",
    "            for th_s, evaluation_score in dict1.items(): \n",
    "                sc = evaluation_score\n",
    "                if sc <= min_score:\n",
    "                    min_score = sc\n",
    "                    th_s_label = np.abs(float(th_s))\n",
    "        indexer = df.index\n",
    "        df.loc[indexer, 'y_pred'] = th_s_label\n",
    "        prediction = np.abs(df['y_pred'])\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_batch_yaw(df, all_models_dict, bin_masks,df_scaled):\n",
    "    running_time = 0.0\n",
    "    futures = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for d, b_masks,df_s in zip(df, bin_masks, df_scaled):\n",
    "        future = client.submit(predict_yaw_batch, d, all_models_dict, b_masks, df_s )\n",
    "        futures.append(future)\n",
    "          \n",
    "    wait(futures, return_when=\"ALL_COMPLETED\")\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    futures = []\n",
    "    running_time = end - start\n",
    "    \n",
    "    return running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipsarros/more_venv2/lib/python3.8/site-packages/distributed/worker.py:4533: UserWarning: Large object of size 82.99 MiB detected in task graph: \n",
      "  ([                     wind speed  pitch angle  ro ...  x 8 columns]])\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_running_time =  1314.8415927886963\n",
      "CPU times: user 1h 29min 59s, sys: 5min 50s, total: 1h 35min 49s\n",
      "Wall time: 1h 35min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "window = 1440\n",
    "running_time = []\n",
    "i = 0\n",
    "\n",
    "batch_data_size = 334\n",
    "\n",
    "df_new = []\n",
    "df_scaled_new = []\n",
    "test_data_bins_new = []\n",
    "df_temp = []\n",
    "df_scaled_temp = []\n",
    "test_data_bins_temp = []\n",
    "total_running_time = 0.0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "while i< len(test_data_scaled[0])-window:\n",
    "    for df, b_masks, df_scaled in zip(test_data, test_data_bins, test_data_scaled):\n",
    "        testDataBins = pd.concat(b_masks,axis=1)\n",
    "        testDataBins.columns = range(12)\n",
    "        \n",
    "        if (counter < batch_data_size):\n",
    "            df_temp.append(df.iloc[i:i+window])\n",
    "            df_scaled_temp.append(df_scaled.iloc[i:i+window])\n",
    "            test_data_bins_temp.append(testDataBins.iloc[i:i+window])\n",
    "            counter = counter +1 \n",
    "        else:\n",
    "            counter = 0\n",
    "            df_new.append(df_temp)\n",
    "            df_scaled_new.append(df_scaled_temp)\n",
    "            test_data_bins_new.append(test_data_bins_temp)\n",
    "            df_temp = []\n",
    "            df_scaled_temp=[]\n",
    "            test_data_bins_temp=[]\n",
    "            \n",
    "            df_temp.append(df.iloc[i:i+window])\n",
    "            df_scaled_temp.append(df_scaled.iloc[i:i+window])\n",
    "            test_data_bins_temp.append(testDataBins.iloc[i:i+window])\n",
    "            counter = counter+1\n",
    "    \n",
    "    df_new.append(df_temp)\n",
    "    df_scaled_new.append(df_scaled_temp)\n",
    "    test_data_bins_new.append(test_data_bins_temp)\n",
    "    \n",
    "    running_time_temp = parallel_batch_yaw(df_new.copy(), all_models_dict,test_data_bins_new.copy(), df_scaled_new.copy() )  \n",
    "    running_time.append(running_time_temp)\n",
    "    total_running_time = total_running_time + running_time_temp\n",
    "    \n",
    "    df_new = []\n",
    "    df_temp=[]\n",
    "    test_data_bins_temp=[]\n",
    "    test_data_bins_new = []\n",
    "    df_scaled_new = []\n",
    "    df_scaled_temp = []\n",
    "    i = i + window\n",
    "    \n",
    "print(\"total_running_time = \", total_running_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73.26486492156982,\n",
       " 73.24556159973145,\n",
       " 65.97510194778442,\n",
       " 63.51662635803223,\n",
       " 64.97564697265625,\n",
       " 62.79744243621826,\n",
       " 62.473812103271484,\n",
       " 63.05023241043091,\n",
       " 58.60575294494629,\n",
       " 62.41235661506653,\n",
       " 65.11336970329285,\n",
       " 66.92150616645813,\n",
       " 65.38022422790527,\n",
       " 61.67776679992676,\n",
       " 66.09904170036316,\n",
       " 77.47049593925476,\n",
       " 64.92107725143433,\n",
       " 63.75164246559143,\n",
       " 68.83843755722046,\n",
       " 64.3506326675415]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
